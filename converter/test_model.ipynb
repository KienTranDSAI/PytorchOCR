{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters in para_state_dict: 33475199\n",
      "out_channels:  230\n",
      "<class 'dict'> {}\n",
      "n_dim: 512, n_position: 256, n_max_char: 41\n",
      "n_dim: 512, n_position: 256, n_max_char: 41\n",
      "paddle: backbone.conv1.weight ---- (32, 3, 3, 3)\n",
      "paddle: backbone.bn1.weight ---- (32,)\n",
      "paddle: backbone.bn1.bias ---- (32,)\n",
      "paddle: backbone.bn1._mean ---- (32,)\n",
      "paddle: backbone.bn1._variance ---- (32,)\n",
      "paddle: backbone.layer1.0.conv1.weight ---- (32, 32, 1, 1)\n",
      "paddle: backbone.layer1.0.bn1.weight ---- (32,)\n",
      "paddle: backbone.layer1.0.bn1.bias ---- (32,)\n",
      "paddle: backbone.layer1.0.bn1._mean ---- (32,)\n",
      "paddle: backbone.layer1.0.bn1._variance ---- (32,)\n",
      "paddle: backbone.layer1.0.conv2.weight ---- (32, 32, 3, 3)\n",
      "paddle: backbone.layer1.0.bn2.weight ---- (32,)\n",
      "paddle: backbone.layer1.0.bn2.bias ---- (32,)\n",
      "paddle: backbone.layer1.0.bn2._mean ---- (32,)\n",
      "paddle: backbone.layer1.0.bn2._variance ---- (32,)\n",
      "paddle: backbone.layer1.0.downsample.0.weight ---- (32, 32, 1, 1)\n",
      "paddle: backbone.layer1.0.downsample.1.weight ---- (32,)\n",
      "paddle: backbone.layer1.0.downsample.1.bias ---- (32,)\n",
      "paddle: backbone.layer1.0.downsample.1._mean ---- (32,)\n",
      "paddle: backbone.layer1.0.downsample.1._variance ---- (32,)\n",
      "paddle: backbone.layer1.1.conv1.weight ---- (32, 32, 1, 1)\n",
      "paddle: backbone.layer1.1.bn1.weight ---- (32,)\n",
      "paddle: backbone.layer1.1.bn1.bias ---- (32,)\n",
      "paddle: backbone.layer1.1.bn1._mean ---- (32,)\n",
      "paddle: backbone.layer1.1.bn1._variance ---- (32,)\n",
      "paddle: backbone.layer1.1.conv2.weight ---- (32, 32, 3, 3)\n",
      "paddle: backbone.layer1.1.bn2.weight ---- (32,)\n",
      "paddle: backbone.layer1.1.bn2.bias ---- (32,)\n",
      "paddle: backbone.layer1.1.bn2._mean ---- (32,)\n",
      "paddle: backbone.layer1.1.bn2._variance ---- (32,)\n",
      "paddle: backbone.layer1.2.conv1.weight ---- (32, 32, 1, 1)\n",
      "paddle: backbone.layer1.2.bn1.weight ---- (32,)\n",
      "paddle: backbone.layer1.2.bn1.bias ---- (32,)\n",
      "paddle: backbone.layer1.2.bn1._mean ---- (32,)\n",
      "paddle: backbone.layer1.2.bn1._variance ---- (32,)\n",
      "paddle: backbone.layer1.2.conv2.weight ---- (32, 32, 3, 3)\n",
      "paddle: backbone.layer1.2.bn2.weight ---- (32,)\n",
      "paddle: backbone.layer1.2.bn2.bias ---- (32,)\n",
      "paddle: backbone.layer1.2.bn2._mean ---- (32,)\n",
      "paddle: backbone.layer1.2.bn2._variance ---- (32,)\n",
      "paddle: backbone.layer2.0.conv1.weight ---- (64, 32, 1, 1)\n",
      "paddle: backbone.layer2.0.bn1.weight ---- (64,)\n",
      "paddle: backbone.layer2.0.bn1.bias ---- (64,)\n",
      "paddle: backbone.layer2.0.bn1._mean ---- (64,)\n",
      "paddle: backbone.layer2.0.bn1._variance ---- (64,)\n",
      "paddle: backbone.layer2.0.conv2.weight ---- (64, 64, 3, 3)\n",
      "paddle: backbone.layer2.0.bn2.weight ---- (64,)\n",
      "paddle: backbone.layer2.0.bn2.bias ---- (64,)\n",
      "paddle: backbone.layer2.0.bn2._mean ---- (64,)\n",
      "paddle: backbone.layer2.0.bn2._variance ---- (64,)\n",
      "paddle: backbone.layer2.0.downsample.0.weight ---- (64, 32, 1, 1)\n",
      "paddle: backbone.layer2.0.downsample.1.weight ---- (64,)\n",
      "paddle: backbone.layer2.0.downsample.1.bias ---- (64,)\n",
      "paddle: backbone.layer2.0.downsample.1._mean ---- (64,)\n",
      "paddle: backbone.layer2.0.downsample.1._variance ---- (64,)\n",
      "paddle: backbone.layer2.1.conv1.weight ---- (64, 64, 1, 1)\n",
      "paddle: backbone.layer2.1.bn1.weight ---- (64,)\n",
      "paddle: backbone.layer2.1.bn1.bias ---- (64,)\n",
      "paddle: backbone.layer2.1.bn1._mean ---- (64,)\n",
      "paddle: backbone.layer2.1.bn1._variance ---- (64,)\n",
      "paddle: backbone.layer2.1.conv2.weight ---- (64, 64, 3, 3)\n",
      "paddle: backbone.layer2.1.bn2.weight ---- (64,)\n",
      "paddle: backbone.layer2.1.bn2.bias ---- (64,)\n",
      "paddle: backbone.layer2.1.bn2._mean ---- (64,)\n",
      "paddle: backbone.layer2.1.bn2._variance ---- (64,)\n",
      "paddle: backbone.layer2.2.conv1.weight ---- (64, 64, 1, 1)\n",
      "paddle: backbone.layer2.2.bn1.weight ---- (64,)\n",
      "paddle: backbone.layer2.2.bn1.bias ---- (64,)\n",
      "paddle: backbone.layer2.2.bn1._mean ---- (64,)\n",
      "paddle: backbone.layer2.2.bn1._variance ---- (64,)\n",
      "paddle: backbone.layer2.2.conv2.weight ---- (64, 64, 3, 3)\n",
      "paddle: backbone.layer2.2.bn2.weight ---- (64,)\n",
      "paddle: backbone.layer2.2.bn2.bias ---- (64,)\n",
      "paddle: backbone.layer2.2.bn2._mean ---- (64,)\n",
      "paddle: backbone.layer2.2.bn2._variance ---- (64,)\n",
      "paddle: backbone.layer2.3.conv1.weight ---- (64, 64, 1, 1)\n",
      "paddle: backbone.layer2.3.bn1.weight ---- (64,)\n",
      "paddle: backbone.layer2.3.bn1.bias ---- (64,)\n",
      "paddle: backbone.layer2.3.bn1._mean ---- (64,)\n",
      "paddle: backbone.layer2.3.bn1._variance ---- (64,)\n",
      "paddle: backbone.layer2.3.conv2.weight ---- (64, 64, 3, 3)\n",
      "paddle: backbone.layer2.3.bn2.weight ---- (64,)\n",
      "paddle: backbone.layer2.3.bn2.bias ---- (64,)\n",
      "paddle: backbone.layer2.3.bn2._mean ---- (64,)\n",
      "paddle: backbone.layer2.3.bn2._variance ---- (64,)\n",
      "paddle: backbone.layer3.0.conv1.weight ---- (128, 64, 1, 1)\n",
      "paddle: backbone.layer3.0.bn1.weight ---- (128,)\n",
      "paddle: backbone.layer3.0.bn1.bias ---- (128,)\n",
      "paddle: backbone.layer3.0.bn1._mean ---- (128,)\n",
      "paddle: backbone.layer3.0.bn1._variance ---- (128,)\n",
      "paddle: backbone.layer3.0.conv2.weight ---- (128, 128, 3, 3)\n",
      "paddle: backbone.layer3.0.bn2.weight ---- (128,)\n",
      "paddle: backbone.layer3.0.bn2.bias ---- (128,)\n",
      "paddle: backbone.layer3.0.bn2._mean ---- (128,)\n",
      "paddle: backbone.layer3.0.bn2._variance ---- (128,)\n",
      "paddle: backbone.layer3.0.downsample.0.weight ---- (128, 64, 1, 1)\n",
      "paddle: backbone.layer3.0.downsample.1.weight ---- (128,)\n",
      "paddle: backbone.layer3.0.downsample.1.bias ---- (128,)\n",
      "paddle: backbone.layer3.0.downsample.1._mean ---- (128,)\n",
      "paddle: backbone.layer3.0.downsample.1._variance ---- (128,)\n",
      "paddle: backbone.layer3.1.conv1.weight ---- (128, 128, 1, 1)\n",
      "paddle: backbone.layer3.1.bn1.weight ---- (128,)\n",
      "paddle: backbone.layer3.1.bn1.bias ---- (128,)\n",
      "paddle: backbone.layer3.1.bn1._mean ---- (128,)\n",
      "paddle: backbone.layer3.1.bn1._variance ---- (128,)\n",
      "paddle: backbone.layer3.1.conv2.weight ---- (128, 128, 3, 3)\n",
      "paddle: backbone.layer3.1.bn2.weight ---- (128,)\n",
      "paddle: backbone.layer3.1.bn2.bias ---- (128,)\n",
      "paddle: backbone.layer3.1.bn2._mean ---- (128,)\n",
      "paddle: backbone.layer3.1.bn2._variance ---- (128,)\n",
      "paddle: backbone.layer3.2.conv1.weight ---- (128, 128, 1, 1)\n",
      "paddle: backbone.layer3.2.bn1.weight ---- (128,)\n",
      "paddle: backbone.layer3.2.bn1.bias ---- (128,)\n",
      "paddle: backbone.layer3.2.bn1._mean ---- (128,)\n",
      "paddle: backbone.layer3.2.bn1._variance ---- (128,)\n",
      "paddle: backbone.layer3.2.conv2.weight ---- (128, 128, 3, 3)\n",
      "paddle: backbone.layer3.2.bn2.weight ---- (128,)\n",
      "paddle: backbone.layer3.2.bn2.bias ---- (128,)\n",
      "paddle: backbone.layer3.2.bn2._mean ---- (128,)\n",
      "paddle: backbone.layer3.2.bn2._variance ---- (128,)\n",
      "paddle: backbone.layer3.3.conv1.weight ---- (128, 128, 1, 1)\n",
      "paddle: backbone.layer3.3.bn1.weight ---- (128,)\n",
      "paddle: backbone.layer3.3.bn1.bias ---- (128,)\n",
      "paddle: backbone.layer3.3.bn1._mean ---- (128,)\n",
      "paddle: backbone.layer3.3.bn1._variance ---- (128,)\n",
      "paddle: backbone.layer3.3.conv2.weight ---- (128, 128, 3, 3)\n",
      "paddle: backbone.layer3.3.bn2.weight ---- (128,)\n",
      "paddle: backbone.layer3.3.bn2.bias ---- (128,)\n",
      "paddle: backbone.layer3.3.bn2._mean ---- (128,)\n",
      "paddle: backbone.layer3.3.bn2._variance ---- (128,)\n",
      "paddle: backbone.layer3.4.conv1.weight ---- (128, 128, 1, 1)\n",
      "paddle: backbone.layer3.4.bn1.weight ---- (128,)\n",
      "paddle: backbone.layer3.4.bn1.bias ---- (128,)\n",
      "paddle: backbone.layer3.4.bn1._mean ---- (128,)\n",
      "paddle: backbone.layer3.4.bn1._variance ---- (128,)\n",
      "paddle: backbone.layer3.4.conv2.weight ---- (128, 128, 3, 3)\n",
      "paddle: backbone.layer3.4.bn2.weight ---- (128,)\n",
      "paddle: backbone.layer3.4.bn2.bias ---- (128,)\n",
      "paddle: backbone.layer3.4.bn2._mean ---- (128,)\n",
      "paddle: backbone.layer3.4.bn2._variance ---- (128,)\n",
      "paddle: backbone.layer3.5.conv1.weight ---- (128, 128, 1, 1)\n",
      "paddle: backbone.layer3.5.bn1.weight ---- (128,)\n",
      "paddle: backbone.layer3.5.bn1.bias ---- (128,)\n",
      "paddle: backbone.layer3.5.bn1._mean ---- (128,)\n",
      "paddle: backbone.layer3.5.bn1._variance ---- (128,)\n",
      "paddle: backbone.layer3.5.conv2.weight ---- (128, 128, 3, 3)\n",
      "paddle: backbone.layer3.5.bn2.weight ---- (128,)\n",
      "paddle: backbone.layer3.5.bn2.bias ---- (128,)\n",
      "paddle: backbone.layer3.5.bn2._mean ---- (128,)\n",
      "paddle: backbone.layer3.5.bn2._variance ---- (128,)\n",
      "paddle: backbone.layer4.0.conv1.weight ---- (256, 128, 1, 1)\n",
      "paddle: backbone.layer4.0.bn1.weight ---- (256,)\n",
      "paddle: backbone.layer4.0.bn1.bias ---- (256,)\n",
      "paddle: backbone.layer4.0.bn1._mean ---- (256,)\n",
      "paddle: backbone.layer4.0.bn1._variance ---- (256,)\n",
      "paddle: backbone.layer4.0.conv2.weight ---- (256, 256, 3, 3)\n",
      "paddle: backbone.layer4.0.bn2.weight ---- (256,)\n",
      "paddle: backbone.layer4.0.bn2.bias ---- (256,)\n",
      "paddle: backbone.layer4.0.bn2._mean ---- (256,)\n",
      "paddle: backbone.layer4.0.bn2._variance ---- (256,)\n",
      "paddle: backbone.layer4.0.downsample.0.weight ---- (256, 128, 1, 1)\n",
      "paddle: backbone.layer4.0.downsample.1.weight ---- (256,)\n",
      "paddle: backbone.layer4.0.downsample.1.bias ---- (256,)\n",
      "paddle: backbone.layer4.0.downsample.1._mean ---- (256,)\n",
      "paddle: backbone.layer4.0.downsample.1._variance ---- (256,)\n",
      "paddle: backbone.layer4.1.conv1.weight ---- (256, 256, 1, 1)\n",
      "paddle: backbone.layer4.1.bn1.weight ---- (256,)\n",
      "paddle: backbone.layer4.1.bn1.bias ---- (256,)\n",
      "paddle: backbone.layer4.1.bn1._mean ---- (256,)\n",
      "paddle: backbone.layer4.1.bn1._variance ---- (256,)\n",
      "paddle: backbone.layer4.1.conv2.weight ---- (256, 256, 3, 3)\n",
      "paddle: backbone.layer4.1.bn2.weight ---- (256,)\n",
      "paddle: backbone.layer4.1.bn2.bias ---- (256,)\n",
      "paddle: backbone.layer4.1.bn2._mean ---- (256,)\n",
      "paddle: backbone.layer4.1.bn2._variance ---- (256,)\n",
      "paddle: backbone.layer4.2.conv1.weight ---- (256, 256, 1, 1)\n",
      "paddle: backbone.layer4.2.bn1.weight ---- (256,)\n",
      "paddle: backbone.layer4.2.bn1.bias ---- (256,)\n",
      "paddle: backbone.layer4.2.bn1._mean ---- (256,)\n",
      "paddle: backbone.layer4.2.bn1._variance ---- (256,)\n",
      "paddle: backbone.layer4.2.conv2.weight ---- (256, 256, 3, 3)\n",
      "paddle: backbone.layer4.2.bn2.weight ---- (256,)\n",
      "paddle: backbone.layer4.2.bn2.bias ---- (256,)\n",
      "paddle: backbone.layer4.2.bn2._mean ---- (256,)\n",
      "paddle: backbone.layer4.2.bn2._variance ---- (256,)\n",
      "paddle: backbone.layer4.3.conv1.weight ---- (256, 256, 1, 1)\n",
      "paddle: backbone.layer4.3.bn1.weight ---- (256,)\n",
      "paddle: backbone.layer4.3.bn1.bias ---- (256,)\n",
      "paddle: backbone.layer4.3.bn1._mean ---- (256,)\n",
      "paddle: backbone.layer4.3.bn1._variance ---- (256,)\n",
      "paddle: backbone.layer4.3.conv2.weight ---- (256, 256, 3, 3)\n",
      "paddle: backbone.layer4.3.bn2.weight ---- (256,)\n",
      "paddle: backbone.layer4.3.bn2.bias ---- (256,)\n",
      "paddle: backbone.layer4.3.bn2._mean ---- (256,)\n",
      "paddle: backbone.layer4.3.bn2._variance ---- (256,)\n",
      "paddle: backbone.layer4.4.conv1.weight ---- (256, 256, 1, 1)\n",
      "paddle: backbone.layer4.4.bn1.weight ---- (256,)\n",
      "paddle: backbone.layer4.4.bn1.bias ---- (256,)\n",
      "paddle: backbone.layer4.4.bn1._mean ---- (256,)\n",
      "paddle: backbone.layer4.4.bn1._variance ---- (256,)\n",
      "paddle: backbone.layer4.4.conv2.weight ---- (256, 256, 3, 3)\n",
      "paddle: backbone.layer4.4.bn2.weight ---- (256,)\n",
      "paddle: backbone.layer4.4.bn2.bias ---- (256,)\n",
      "paddle: backbone.layer4.4.bn2._mean ---- (256,)\n",
      "paddle: backbone.layer4.4.bn2._variance ---- (256,)\n",
      "paddle: backbone.layer4.5.conv1.weight ---- (256, 256, 1, 1)\n",
      "paddle: backbone.layer4.5.bn1.weight ---- (256,)\n",
      "paddle: backbone.layer4.5.bn1.bias ---- (256,)\n",
      "paddle: backbone.layer4.5.bn1._mean ---- (256,)\n",
      "paddle: backbone.layer4.5.bn1._variance ---- (256,)\n",
      "paddle: backbone.layer4.5.conv2.weight ---- (256, 256, 3, 3)\n",
      "paddle: backbone.layer4.5.bn2.weight ---- (256,)\n",
      "paddle: backbone.layer4.5.bn2.bias ---- (256,)\n",
      "paddle: backbone.layer4.5.bn2._mean ---- (256,)\n",
      "paddle: backbone.layer4.5.bn2._variance ---- (256,)\n",
      "paddle: backbone.layer5.0.conv1.weight ---- (512, 256, 1, 1)\n",
      "paddle: backbone.layer5.0.bn1.weight ---- (512,)\n",
      "paddle: backbone.layer5.0.bn1.bias ---- (512,)\n",
      "paddle: backbone.layer5.0.bn1._mean ---- (512,)\n",
      "paddle: backbone.layer5.0.bn1._variance ---- (512,)\n",
      "paddle: backbone.layer5.0.conv2.weight ---- (512, 512, 3, 3)\n",
      "paddle: backbone.layer5.0.bn2.weight ---- (512,)\n",
      "paddle: backbone.layer5.0.bn2.bias ---- (512,)\n",
      "paddle: backbone.layer5.0.bn2._mean ---- (512,)\n",
      "paddle: backbone.layer5.0.bn2._variance ---- (512,)\n",
      "paddle: backbone.layer5.0.downsample.0.weight ---- (512, 256, 1, 1)\n",
      "paddle: backbone.layer5.0.downsample.1.weight ---- (512,)\n",
      "paddle: backbone.layer5.0.downsample.1.bias ---- (512,)\n",
      "paddle: backbone.layer5.0.downsample.1._mean ---- (512,)\n",
      "paddle: backbone.layer5.0.downsample.1._variance ---- (512,)\n",
      "paddle: backbone.layer5.1.conv1.weight ---- (512, 512, 1, 1)\n",
      "paddle: backbone.layer5.1.bn1.weight ---- (512,)\n",
      "paddle: backbone.layer5.1.bn1.bias ---- (512,)\n",
      "paddle: backbone.layer5.1.bn1._mean ---- (512,)\n",
      "paddle: backbone.layer5.1.bn1._variance ---- (512,)\n",
      "paddle: backbone.layer5.1.conv2.weight ---- (512, 512, 3, 3)\n",
      "paddle: backbone.layer5.1.bn2.weight ---- (512,)\n",
      "paddle: backbone.layer5.1.bn2.bias ---- (512,)\n",
      "paddle: backbone.layer5.1.bn2._mean ---- (512,)\n",
      "paddle: backbone.layer5.1.bn2._variance ---- (512,)\n",
      "paddle: backbone.layer5.2.conv1.weight ---- (512, 512, 1, 1)\n",
      "paddle: backbone.layer5.2.bn1.weight ---- (512,)\n",
      "paddle: backbone.layer5.2.bn1.bias ---- (512,)\n",
      "paddle: backbone.layer5.2.bn1._mean ---- (512,)\n",
      "paddle: backbone.layer5.2.bn1._variance ---- (512,)\n",
      "paddle: backbone.layer5.2.conv2.weight ---- (512, 512, 3, 3)\n",
      "paddle: backbone.layer5.2.bn2.weight ---- (512,)\n",
      "paddle: backbone.layer5.2.bn2.bias ---- (512,)\n",
      "paddle: backbone.layer5.2.bn2._mean ---- (512,)\n",
      "paddle: backbone.layer5.2.bn2._variance ---- (512,)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_mask.position_enc.pos_table ---- (1, 256, 512)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_mask.layer_stack.0.slf_attn.w_qs.weight ---- (512, 512)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_mask.layer_stack.0.slf_attn.w_qs.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_mask.layer_stack.0.slf_attn.w_ks.weight ---- (512, 512)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_mask.layer_stack.0.slf_attn.w_ks.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_mask.layer_stack.0.slf_attn.w_vs.weight ---- (512, 512)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_mask.layer_stack.0.slf_attn.w_vs.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_mask.layer_stack.0.slf_attn.layer_norm.weight ---- (512,)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_mask.layer_stack.0.slf_attn.layer_norm.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_mask.layer_stack.0.slf_attn.fc.weight ---- (512, 512)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_mask.layer_stack.0.slf_attn.fc.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_mask.layer_stack.0.pos_ffn.w_1.weight ---- (2048, 512, 1)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_mask.layer_stack.0.pos_ffn.w_1.bias ---- (2048,)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_mask.layer_stack.0.pos_ffn.w_2.weight ---- (512, 2048, 1)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_mask.layer_stack.0.pos_ffn.w_2.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_mask.layer_stack.0.pos_ffn.layer_norm.weight ---- (512,)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_mask.layer_stack.0.pos_ffn.layer_norm.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_mask.layer_stack.1.slf_attn.w_qs.weight ---- (512, 512)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_mask.layer_stack.1.slf_attn.w_qs.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_mask.layer_stack.1.slf_attn.w_ks.weight ---- (512, 512)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_mask.layer_stack.1.slf_attn.w_ks.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_mask.layer_stack.1.slf_attn.w_vs.weight ---- (512, 512)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_mask.layer_stack.1.slf_attn.w_vs.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_mask.layer_stack.1.slf_attn.layer_norm.weight ---- (512,)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_mask.layer_stack.1.slf_attn.layer_norm.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_mask.layer_stack.1.slf_attn.fc.weight ---- (512, 512)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_mask.layer_stack.1.slf_attn.fc.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_mask.layer_stack.1.pos_ffn.w_1.weight ---- (2048, 512, 1)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_mask.layer_stack.1.pos_ffn.w_1.bias ---- (2048,)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_mask.layer_stack.1.pos_ffn.w_2.weight ---- (512, 2048, 1)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_mask.layer_stack.1.pos_ffn.w_2.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_mask.layer_stack.1.pos_ffn.layer_norm.weight ---- (512,)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_mask.layer_stack.1.pos_ffn.layer_norm.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_mask.layer_norm.weight ---- (512,)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_mask.layer_norm.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_WCL.position_enc.pos_table ---- (1, 256, 512)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_WCL.layer_stack.0.slf_attn.w_qs.weight ---- (512, 512)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_WCL.layer_stack.0.slf_attn.w_qs.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_WCL.layer_stack.0.slf_attn.w_ks.weight ---- (512, 512)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_WCL.layer_stack.0.slf_attn.w_ks.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_WCL.layer_stack.0.slf_attn.w_vs.weight ---- (512, 512)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_WCL.layer_stack.0.slf_attn.w_vs.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_WCL.layer_stack.0.slf_attn.layer_norm.weight ---- (512,)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_WCL.layer_stack.0.slf_attn.layer_norm.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_WCL.layer_stack.0.slf_attn.fc.weight ---- (512, 512)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_WCL.layer_stack.0.slf_attn.fc.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_WCL.layer_stack.0.pos_ffn.w_1.weight ---- (2048, 512, 1)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_WCL.layer_stack.0.pos_ffn.w_1.bias ---- (2048,)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_WCL.layer_stack.0.pos_ffn.w_2.weight ---- (512, 2048, 1)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_WCL.layer_stack.0.pos_ffn.w_2.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_WCL.layer_stack.0.pos_ffn.layer_norm.weight ---- (512,)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_WCL.layer_stack.0.pos_ffn.layer_norm.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_WCL.layer_norm.weight ---- (512,)\n",
      "paddle: head.MLM_VRM.MLM.MLM_SequenceModeling_WCL.layer_norm.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.MLM.pos_embedding.weight ---- (40, 512)\n",
      "paddle: head.MLM_VRM.MLM.w0_linear.weight ---- (1, 256)\n",
      "paddle: head.MLM_VRM.MLM.w0_linear.bias ---- (256,)\n",
      "paddle: head.MLM_VRM.MLM.wv.weight ---- (512, 512)\n",
      "paddle: head.MLM_VRM.MLM.wv.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.MLM.we.weight ---- (512, 1)\n",
      "paddle: head.MLM_VRM.MLM.we.bias ---- (1,)\n",
      "paddle: head.MLM_VRM.SequenceModeling.position_enc.pos_table ---- (1, 256, 512)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.0.slf_attn.w_qs.weight ---- (512, 512)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.0.slf_attn.w_qs.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.0.slf_attn.w_ks.weight ---- (512, 512)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.0.slf_attn.w_ks.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.0.slf_attn.w_vs.weight ---- (512, 512)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.0.slf_attn.w_vs.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.0.slf_attn.layer_norm.weight ---- (512,)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.0.slf_attn.layer_norm.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.0.slf_attn.fc.weight ---- (512, 512)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.0.slf_attn.fc.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.0.pos_ffn.w_1.weight ---- (2048, 512, 1)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.0.pos_ffn.w_1.bias ---- (2048,)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.0.pos_ffn.w_2.weight ---- (512, 2048, 1)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.0.pos_ffn.w_2.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.0.pos_ffn.layer_norm.weight ---- (512,)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.0.pos_ffn.layer_norm.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.1.slf_attn.w_qs.weight ---- (512, 512)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.1.slf_attn.w_qs.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.1.slf_attn.w_ks.weight ---- (512, 512)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.1.slf_attn.w_ks.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.1.slf_attn.w_vs.weight ---- (512, 512)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.1.slf_attn.w_vs.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.1.slf_attn.layer_norm.weight ---- (512,)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.1.slf_attn.layer_norm.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.1.slf_attn.fc.weight ---- (512, 512)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.1.slf_attn.fc.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.1.pos_ffn.w_1.weight ---- (2048, 512, 1)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.1.pos_ffn.w_1.bias ---- (2048,)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.1.pos_ffn.w_2.weight ---- (512, 2048, 1)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.1.pos_ffn.w_2.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.1.pos_ffn.layer_norm.weight ---- (512,)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.1.pos_ffn.layer_norm.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.2.slf_attn.w_qs.weight ---- (512, 512)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.2.slf_attn.w_qs.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.2.slf_attn.w_ks.weight ---- (512, 512)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.2.slf_attn.w_ks.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.2.slf_attn.w_vs.weight ---- (512, 512)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.2.slf_attn.w_vs.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.2.slf_attn.layer_norm.weight ---- (512,)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.2.slf_attn.layer_norm.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.2.slf_attn.fc.weight ---- (512, 512)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.2.slf_attn.fc.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.2.pos_ffn.w_1.weight ---- (2048, 512, 1)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.2.pos_ffn.w_1.bias ---- (2048,)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.2.pos_ffn.w_2.weight ---- (512, 2048, 1)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.2.pos_ffn.w_2.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.2.pos_ffn.layer_norm.weight ---- (512,)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_stack.2.pos_ffn.layer_norm.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_norm.weight ---- (512,)\n",
      "paddle: head.MLM_VRM.SequenceModeling.layer_norm.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.Prediction.pp.f0_embedding.weight ---- (41, 512)\n",
      "paddle: head.MLM_VRM.Prediction.pp.w0.weight ---- (41, 256)\n",
      "paddle: head.MLM_VRM.Prediction.pp.w0.bias ---- (256,)\n",
      "paddle: head.MLM_VRM.Prediction.pp.wv.weight ---- (512, 512)\n",
      "paddle: head.MLM_VRM.Prediction.pp.wv.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.Prediction.pp.we.weight ---- (512, 41)\n",
      "paddle: head.MLM_VRM.Prediction.pp.we.bias ---- (41,)\n",
      "paddle: head.MLM_VRM.Prediction.pp_share.f0_embedding.weight ---- (41, 512)\n",
      "paddle: head.MLM_VRM.Prediction.pp_share.w0.weight ---- (41, 256)\n",
      "paddle: head.MLM_VRM.Prediction.pp_share.w0.bias ---- (256,)\n",
      "paddle: head.MLM_VRM.Prediction.pp_share.wv.weight ---- (512, 512)\n",
      "paddle: head.MLM_VRM.Prediction.pp_share.wv.bias ---- (512,)\n",
      "paddle: head.MLM_VRM.Prediction.pp_share.we.weight ---- (512, 41)\n",
      "paddle: head.MLM_VRM.Prediction.pp_share.we.bias ---- (41,)\n",
      "paddle: head.MLM_VRM.Prediction.w_vrm.weight ---- (512, 230)\n",
      "paddle: head.MLM_VRM.Prediction.w_vrm.bias ---- (230,)\n",
      "paddle: head.MLM_VRM.Prediction.w_share.weight ---- (512, 230)\n",
      "paddle: head.MLM_VRM.Prediction.w_share.bias ---- (230,)\n",
      "model is loaded.\n",
      "model is loaded: /raid/kientdt/shared_drive_cv/ocr/kientdt/PaddleOCR/output/rec/vi_r45_visionlan_19_2/best_accuracy\n",
      "Total number of parameters in self.net: 33475199\n",
      "model is saved: visionlan_ver1.pth\n",
      "done.\n",
      "BaseModel(\n",
      "  (backbone): ResNet45(\n",
      "    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (4): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (5): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (4): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (5): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer5): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): VLHead(\n",
      "    (MLM_VRM): MLM_VRM(\n",
      "      (MLM): MLM(\n",
      "        (MLM_SequenceModeling_mask): Transformer_Encoder(\n",
      "          (position_enc): PositionalEncoding()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer_stack): ModuleList(\n",
      "            (0-1): 2 x EncoderLayer(\n",
      "              (slf_attn): MultiHeadAttention(\n",
      "                (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (attention): ScaledDotProductAttention(\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (softmax): Softmax(dim=2)\n",
      "                )\n",
      "                (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (pos_ffn): PositionwiseFeedForward(\n",
      "                (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "                (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "                (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        )\n",
      "        (MLM_SequenceModeling_WCL): Transformer_Encoder(\n",
      "          (position_enc): PositionalEncoding()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer_stack): ModuleList(\n",
      "            (0): EncoderLayer(\n",
      "              (slf_attn): MultiHeadAttention(\n",
      "                (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (attention): ScaledDotProductAttention(\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (softmax): Softmax(dim=2)\n",
      "                )\n",
      "                (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (pos_ffn): PositionwiseFeedForward(\n",
      "                (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "                (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "                (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        )\n",
      "        (pos_embedding): Embedding(40, 512)\n",
      "        (w0_linear): Linear(in_features=1, out_features=256, bias=True)\n",
      "        (wv): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (active): Tanh()\n",
      "        (we): Linear(in_features=512, out_features=1, bias=True)\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (SequenceModeling): Transformer_Encoder(\n",
      "        (position_enc): PositionalEncoding()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (layer_stack): ModuleList(\n",
      "          (0-2): 3 x EncoderLayer(\n",
      "            (slf_attn): MultiHeadAttention(\n",
      "              (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (attention): ScaledDotProductAttention(\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (softmax): Softmax(dim=2)\n",
      "              )\n",
      "              (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (pos_ffn): PositionwiseFeedForward(\n",
      "              (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "              (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "              (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (Prediction): Prediction(\n",
      "        (pp): PP_layer(\n",
      "          (f0_embedding): Embedding(41, 512)\n",
      "          (w0): Linear(in_features=41, out_features=256, bias=True)\n",
      "          (wv): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (we): Linear(in_features=512, out_features=41, bias=True)\n",
      "          (active): Tanh()\n",
      "          (softmax): Softmax(dim=2)\n",
      "        )\n",
      "        (pp_share): PP_layer(\n",
      "          (f0_embedding): Embedding(41, 512)\n",
      "          (w0): Linear(in_features=41, out_features=256, bias=True)\n",
      "          (wv): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (we): Linear(in_features=512, out_features=41, bias=True)\n",
      "          (active): Tanh()\n",
      "          (softmax): Softmax(dim=2)\n",
      "        )\n",
      "        (w_vrm): Linear(in_features=512, out_features=230, bias=True)\n",
      "        (w_share): Linear(in_features=512, out_features=230, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# https://zhuanlan.zhihu.com/p/335753926\n",
    "import os, sys\n",
    "sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(\"__file__\"))))\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from pytorchocr.base_ocr_v20 import BaseOCRV20\n",
    "\n",
    "class PPOCRv3RecConverter(BaseOCRV20):\n",
    "    def __init__(self, config, paddle_pretrained_model_path, **kwargs):\n",
    "        para_state_dict, opti_state_dict = self.read_paddle_weights(paddle_pretrained_model_path)\n",
    "        para_state_dict = self.del_invalid_state_dict(para_state_dict)\n",
    "        total_params = sum(p.size if isinstance(p, np.ndarray) else p.numel() for p in para_state_dict.values())\n",
    "        print(f'Total number of parameters in para_state_dict: {total_params}')\n",
    "        out_channels = list(para_state_dict.values())[-1].shape[0]\n",
    "        print('out_channels: ', out_channels)\n",
    "        print(type(kwargs), kwargs)\n",
    "        kwargs['out_channels'] = out_channels\n",
    "        super(PPOCRv3RecConverter, self).__init__(config, **kwargs)\n",
    "        # self.load_paddle_weights(paddle_pretrained_model_path)\n",
    "        self.load_paddle_weights([para_state_dict, opti_state_dict])\n",
    "        print('model is loaded: {}'.format(paddle_pretrained_model_path))\n",
    "        otal_params = sum(p.numel() for p in self.net.parameters())\n",
    "        print(f'Total number of parameters in self.net: {total_params}')\n",
    "        self.net.eval()\n",
    "\n",
    "\n",
    "    def del_invalid_state_dict(self, para_state_dict):\n",
    "        new_state_dict = OrderedDict()\n",
    "        for i, (k,v) in enumerate(para_state_dict.items()):\n",
    "            if k.startswith('Teacher.'):\n",
    "                continue\n",
    "\n",
    "            elif k.startswith('Student.head.sar_head.'):\n",
    "                continue\n",
    "\n",
    "            else:\n",
    "                new_state_dict[k] = v\n",
    "        return new_state_dict\n",
    "\n",
    "\n",
    "    def load_paddle_weights(self, paddle_weights):\n",
    "        para_state_dict, opti_state_dict = paddle_weights\n",
    "        [print('paddle: {} ---- {}'.format(k, v.shape)) for k, v in para_state_dict.items()]\n",
    "        # [print('pytorch: {} ---- {}'.format(k, v.shape)) for k, v in self.net.state_dict().items()]\n",
    "\n",
    "        for k,v in self.net.state_dict().items():\n",
    "            if k.endswith('num_batches_tracked'):\n",
    "                continue\n",
    "\n",
    "            ppname = k\n",
    "            ppname = ppname.replace('.running_mean', '._mean')\n",
    "            ppname = ppname.replace('.running_var', '._variance')\n",
    "            ppname = ppname.replace('neck.encoder.', 'head.ctc_encoder.encoder.')\n",
    "            ppname = ppname.replace('head.fc.', 'head.ctc_head.fc.')\n",
    "\n",
    "            try:\n",
    "                try:\n",
    "                    if ppname.endswith('fc1.weight') or ppname.endswith('fc2.weight') \\\n",
    "                            or ppname.endswith('fc.weight') or ppname.endswith('qkv.weight') \\\n",
    "                            or ppname.endswith('proj.weight') or ppname.endswith(\"MLM_VRM.MLM.w0_linear.weight\") \\\n",
    "                                or ppname.endswith(\"MLM_VRM.MLM.we.weight\") \\\n",
    "                                    or ppname.endswith(\"MLM_VRM.Prediction.pp.w0.weight\") \\\n",
    "                                        or ppname.endswith(\"MLM_VRM.Prediction.pp.we.weight\") or (\"weight\" in ppname and \"MLM_VRM\") \\\n",
    "                                            and (\"backbone\" not in ppname) \\\n",
    "                                                and (\"MLM_SequenceModeling_mask\" not in ppname) \\\n",
    "                                                    and (\"MLM_SequenceModeling_WCL\" not in ppname): # or (\"weight\" in ppname and \"MLM_VRM\")\n",
    "                        # print(\"Transpose!\")\n",
    "                        self.net.state_dict()[k].copy_(torch.Tensor(para_state_dict[ppname].T))\n",
    "                    else:\n",
    "                        # print(\"No transpose\")\n",
    "\n",
    "                        self.net.state_dict()[k].copy_(torch.Tensor(para_state_dict[ppname]))\n",
    "                except:\n",
    "                    self.net.state_dict()[k].copy_(torch.Tensor(para_state_dict[ppname]))\n",
    "            except Exception as e:\n",
    "                print('pytorch: {}, {}'.format(k, v.size()))\n",
    "                print('paddle: {}, {}'.format(ppname, para_state_dict[ppname].shape))\n",
    "                raise e\n",
    "\n",
    "        print('model is loaded.')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import argparse, json, textwrap, sys, os\n",
    "\n",
    "    # parser = argparse.ArgumentParser()\n",
    "    # parser.add_argument(\"--src_model_path\", type=str, help='Assign the paddleOCR trained model(best_accuracy)')\n",
    "    # args = parser.parse_args()\n",
    "    src_model_path = \"/raid/kientdt/shared_drive_cv/ocr/kientdt/PaddleOCR/output/rec/vi_r45_visionlan_19_2\"\n",
    "    cfg = {'model_type':'rec',\n",
    "           'algorithm':'VisionLAN',\n",
    "           'Transform':None,\n",
    "           'Backbone':{'name':'ResNet45',\n",
    "                       'strides': [2, 2, 2, 1, 1]},\n",
    "           'Head':{'name':'VLHead',\n",
    "            \"n_layers\": 3,\n",
    "            \"n_position\": 256,\n",
    "            \"n_dim\": 512,\n",
    "            \"max_text_length\": 40,\n",
    "            \"training_step\": 'LA'}\n",
    "           }\n",
    "    paddle_pretrained_model_path = os.path.join(os.path.abspath(src_model_path), 'best_accuracy')\n",
    "    converter = PPOCRv3RecConverter(cfg, paddle_pretrained_model_path)\n",
    "    save_basename = os.path.basename(os.path.abspath(src_model_path))\n",
    "\n",
    "    save_name = 'visionlan_ver1.pth'\n",
    "    converter.save_pytorch_weights(save_name)\n",
    "    print('done.')\n",
    "    print(converter.net)\n",
    "\n",
    "\n",
    "\n",
    "####Model path: /raid/kientdt/shared_drive_cv/ocr/kientdt/PaddleOCR/output/rec/r45_visionlan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = converter.net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModel(\n",
       "  (backbone): ResNet45(\n",
       "    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (head): VLHead(\n",
       "    (MLM_VRM): MLM_VRM(\n",
       "      (MLM): MLM(\n",
       "        (MLM_SequenceModeling_mask): Transformer_Encoder(\n",
       "          (position_enc): PositionalEncoding()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_stack): ModuleList(\n",
       "            (0-1): 2 x EncoderLayer(\n",
       "              (slf_attn): MultiHeadAttention(\n",
       "                (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (attention): ScaledDotProductAttention(\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (softmax): Softmax(dim=2)\n",
       "                )\n",
       "                (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (fc): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (pos_ffn): PositionwiseFeedForward(\n",
       "                (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
       "                (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
       "                (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (MLM_SequenceModeling_WCL): Transformer_Encoder(\n",
       "          (position_enc): PositionalEncoding()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_stack): ModuleList(\n",
       "            (0): EncoderLayer(\n",
       "              (slf_attn): MultiHeadAttention(\n",
       "                (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (attention): ScaledDotProductAttention(\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (softmax): Softmax(dim=2)\n",
       "                )\n",
       "                (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (fc): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (pos_ffn): PositionwiseFeedForward(\n",
       "                (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
       "                (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
       "                (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_embedding): Embedding(40, 512)\n",
       "        (w0_linear): Linear(in_features=1, out_features=256, bias=True)\n",
       "        (wv): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (active): Tanh()\n",
       "        (we): Linear(in_features=512, out_features=1, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (SequenceModeling): Transformer_Encoder(\n",
       "        (position_enc): PositionalEncoding()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer_stack): ModuleList(\n",
       "          (0-2): 3 x EncoderLayer(\n",
       "            (slf_attn): MultiHeadAttention(\n",
       "              (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (attention): ScaledDotProductAttention(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (softmax): Softmax(dim=2)\n",
       "              )\n",
       "              (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (pos_ffn): PositionwiseFeedForward(\n",
       "              (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
       "              (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
       "              (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "      (Prediction): Prediction(\n",
       "        (pp): PP_layer(\n",
       "          (f0_embedding): Embedding(41, 512)\n",
       "          (w0): Linear(in_features=41, out_features=256, bias=True)\n",
       "          (wv): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (we): Linear(in_features=512, out_features=41, bias=True)\n",
       "          (active): Tanh()\n",
       "          (softmax): Softmax(dim=2)\n",
       "        )\n",
       "        (pp_share): PP_layer(\n",
       "          (f0_embedding): Embedding(41, 512)\n",
       "          (w0): Linear(in_features=41, out_features=256, bias=True)\n",
       "          (wv): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (we): Linear(in_features=512, out_features=41, bias=True)\n",
       "          (active): Tanh()\n",
       "          (softmax): Softmax(dim=2)\n",
       "        )\n",
       "        (w_vrm): Linear(in_features=512, out_features=230, bias=True)\n",
       "        (w_share): Linear(in_features=512, out_features=230, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# # Load the image\n",
    "# image_path = '/raid/kientdt/shared_drive_cv/ocr/kientdt/PaddleOCR2Pytorch/img_169.jpg'\n",
    "# image = cv2.imread(image_path)\n",
    "\n",
    "# # Convert the image to RGB (if it's in BGR)\n",
    "# image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# # Resize the image to the expected input size (e.g., 32x100)\n",
    "# image_resized = cv2.resize(image, (100, 32))\n",
    "\n",
    "# # Normalize the image\n",
    "# image_normalized = image_resized / 255.0\n",
    "\n",
    "# # Convert to tensor and add batch dimension\n",
    "# image_tensor = torch.tensor(image_normalized).permute(2, 0, 1).unsqueeze(0).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorchocr.postprocess.rec_postprocess import VLLabelDecode\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "decoder = VLLabelDecode(\"/raid/kientdt/shared_drive_cv/ocr/kientdt/PaddleOCR/ppocr/utils/dict/my_vi_dict.txt\", False, max_text_length = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=138x31>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = \"/raid/kientdt/shared_drive_cv/ocr/hieunq/PDFs_130125/TNR_Bold/train/img_9646.jpg\"\n",
    "Image.open(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat: torch.Size([1, 512, 8, 32])\n",
      "target: None\n",
      "x: torch.Size([1, 256, 512])\n",
      "1.enc_output at transformer: torch.Size([1, 256, 512])\n",
      "enc_output at transformer: torch.Size([1, 256, 512])\n",
      "contextual_feature: torch.Size([1, 256, 512])\n",
      "cnn_feature: torch.Size([1, 256, 512])\n",
      "reading_order: torch.Size([1, 41, 512])\n",
      "enc_output: torch.Size([1, 256, 512])\n",
      "self.wv: Linear(in_features=512, out_features=512, bias=True), self.w0: Linear(in_features=41, out_features=256, bias=True)\n",
      "t.permute(0,2,1): torch.Size([1, 256, 512]), self.wv(enc_output): torch.Size([1, 256, 512])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if True:\n",
    "    # image_path = '/raid/kientdt/shared_drive_cv/ocr/kientdt/PaddleOCR2Pytorch/img_169.jpg'\n",
    "    # output_txt = './demo/predictions.txt'\n",
    "    # image_list = os.listdir(image_path)\n",
    "    img_width = 256\n",
    "    img_height = 64\n",
    "    transf = transforms.ToTensor()\n",
    "    # test_acc_counter = Attention_AR_counter('\\ntest accuracy: ', \"/raid/kientdt/shared_drive_cv/ocr/kientdt/PaddleOCR/ppocr/utils/dict/my_vi_dict.txt\",\n",
    "    #                                         False)\n",
    "\n",
    "    model.eval()\n",
    "    if True:\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        img = img.resize((img_width, img_height))\n",
    "        img = transf(img)\n",
    "        img = torch.unsqueeze(img,dim = 0)\n",
    "        target = ''\n",
    "        output = model(img)\n",
    "        # pre_string = test_acc_counter.convert(output, 5)\n",
    "        # print('pre_string:',pre_string[0])\n",
    "        # with open(output_txt,'a') as f:\n",
    "            # f.write(img_name+':'+pre_string[0]+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (229) must match the existing size (230) at non-singleton dimension 1.  Target sizes: [1, 229].  Tensor sizes: [230]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/raid/project_drive/CV/ocr/kientdt/PaddleOCR2Pytorch/pytorchocr/postprocess/rec_postprocess.py:916\u001b[0m, in \u001b[0;36mVLLabelDecode.__call__\u001b[0;34m(self, preds, label, length, *args, **kwargs)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01min\u001b[39;00m out_length \u001b[38;5;129;01mand\u001b[39;00m now_step \u001b[38;5;241m<\u001b[39m nsteps:\n\u001b[1;32m    915\u001b[0m     tmp_result \u001b[38;5;241m=\u001b[39m text_pre[now_step, :, :]\n\u001b[0;32m--> 916\u001b[0m     \u001b[43mout_res\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnow_step\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m tmp_result\n\u001b[1;32m    917\u001b[0m     tmp_result \u001b[38;5;241m=\u001b[39m tmp_result\u001b[38;5;241m.\u001b[39mtopk(\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(b):\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (229) must match the existing size (230) at non-singleton dimension 1.  Target sizes: [1, 229].  Tensor sizes: [230]"
     ]
    }
   ],
   "source": [
    "decoder(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 2.1689, -3.8158, -5.5368,  ...,  4.0971,  0.1235, -1.4682]],\n",
       " \n",
       "         [[-0.4243, -0.3389, -0.9833,  ...,  6.4294,  3.0310, -4.8024]],\n",
       " \n",
       "         [[ 3.9689, -1.9176, -4.6427,  ...,  4.8496, -1.2137, -2.9893]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 1.8408, -0.7990, -2.8129,  ...,  7.4797,  0.8752, -3.5223]],\n",
       " \n",
       "         [[ 3.3813, -0.3652, -3.3112,  ...,  6.2396,  0.0144, -3.6870]],\n",
       " \n",
       "         [[ 2.4544, -0.6290, -3.0637,  ...,  6.4031,  0.6885, -3.9720]]],\n",
       "        grad_fn=<TransposeBackward0>),\n",
       " tensor([[[1.0607, 0.0000, 0.0591,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0370, 0.0000,  ..., 0.0000, 0.0000, 0.9042],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.7529, 0.0000, 1.2725],\n",
       "          ...,\n",
       "          [0.0000, 1.7642, 0.0000,  ..., 0.0000, 2.3638, 0.0000],\n",
       "          [0.0000, 3.0241, 0.0000,  ..., 0.0000, 3.1049, 0.0000],\n",
       "          [3.6165, 0.3620, 3.1657,  ..., 0.0000, 0.7767, 0.3339]]],\n",
       "        grad_fn=<TransposeBackward0>))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
